{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for **\"Blind restoration of a JPEG-compressed image\"** and **\"Blind image denoising\"** figures. Select `fname` below to switch between the two.\n",
    "\n",
    "- To see overfitting set `num_iter` to a large value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named torch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4e982029bee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/guofeng/Git/hub/deep-image-prior/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtexture_nets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_texture_nets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# from model_pad_ds import Net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/guofeng/Git/hub/deep-image-prior/models/skip.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m def skip(\n",
      "\u001b[0;31mImportError\u001b[0m: No module named torch"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from models import *\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from utils.denoising_utils import *\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "imsize =-1\n",
    "PLOT = True\n",
    "sigma = 25\n",
    "sigma_ = sigma/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## deJPEG \n",
    "fname = 'data/denoising/snail.jpg'\n",
    "\n",
    "## denoising\n",
    "# fname = 'data/denoising/F16_GT.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fname == 'data/denoising/snail.jpg':\n",
    "    img_noisy_pil = crop_image(get_image(fname, imsize)[0], d=32)\n",
    "    img_noisy_np = pil_to_np(img_noisy_pil)\n",
    "    \n",
    "    # As we don't have ground truth\n",
    "    img_pil = img_noisy_pil\n",
    "    img_np = img_noisy_np\n",
    "    \n",
    "    if PLOT:\n",
    "        plot_image_grid([img_np], 4, 5);\n",
    "        \n",
    "elif fname == 'data/denoising/F16_GT.png':\n",
    "    # Add synthetic noise\n",
    "    img_pil = crop_image(get_image(fname, imsize)[0], d=32)\n",
    "    img_np = pil_to_np(img_pil)\n",
    "    \n",
    "    img_noisy_pil, img_noisy_np = get_noisy_image(img_np, sigma_)\n",
    "    \n",
    "    if PLOT:\n",
    "        plot_image_grid([img_np, img_noisy_np], 4, 6);\n",
    "else:\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = 'noise' # 'meshgrid'\n",
    "pad = 'reflection'\n",
    "OPT_OVER = 'net' # 'net,input'\n",
    "\n",
    "reg_noise_std = 1./30. # set to 1./20. for sigma=50\n",
    "LR = 0.01\n",
    "\n",
    "OPTIMIZER='adam' # 'LBFGS'\n",
    "show_every = 500\n",
    "\n",
    "if fname == 'data/denoising/snail.jpg':\n",
    "    num_iter=2400\n",
    "    input_depth = 3\n",
    "    figsize = 5 \n",
    "    \n",
    "    net = skip(\n",
    "                input_depth, 3, \n",
    "                num_channels_down = [8, 16, 32, 64, 128], \n",
    "                num_channels_up   = [8, 16, 32, 64, 128],\n",
    "                num_channels_skip = [0, 0, 0, 4, 4], \n",
    "                upsample_mode='bilinear',\n",
    "                need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU')\n",
    "\n",
    "    net = net.type(dtype)\n",
    "\n",
    "elif fname == 'data/denoising/F16_GT.png':\n",
    "    num_iter = 3000\n",
    "    input_depth = 32 \n",
    "    figsize = 4 \n",
    "    \n",
    "    net = get_net(input_depth, 'skip', pad,\n",
    "                  skip_n33d=128, \n",
    "                  skip_n33u=128, \n",
    "                  skip_n11=4, \n",
    "                  num_scales=5,\n",
    "                  upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "else:\n",
    "    assert False\n",
    "    \n",
    "net_input = get_noise(input_depth, INPUT, (img_pil.size[1], img_pil.size[0])).type(dtype).detach()\n",
    "\n",
    "# Compute number of parameters\n",
    "s  = sum([np.prod(list(p.size())) for p in net.parameters()]); \n",
    "print ('Number of params: %d' % s)\n",
    "\n",
    "# Loss\n",
    "mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "img_noisy_var = np_to_var(img_noisy_np).type(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net_input_saved = net_input.data.clone()\n",
    "noise = net_input.data.clone()\n",
    "\n",
    "\n",
    "i = 0\n",
    "def closure():\n",
    "    \n",
    "    global i\n",
    "    \n",
    "    if reg_noise_std > 0:\n",
    "        net_input.data = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "    \n",
    "    out = net(net_input)\n",
    "   \n",
    "    total_loss = mse(out, img_noisy_var)\n",
    "    total_loss.backward()\n",
    "        \n",
    "    print ('Iteration %05d    Loss %f' % (i, total_loss.data[0]), '\\r', end='')\n",
    "    if  PLOT and i % show_every == 0:\n",
    "        out_np = var_to_np(out)\n",
    "        plot_image_grid([np.clip(out_np, 0, 1)], factor=figsize, nrow=1)\n",
    "        \n",
    "        np_to_pil(var_to_np(net(net_input))).save('F16/%d.png' % i)\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "p = get_params(OPT_OVER, net, net_input)\n",
    "optimize(OPTIMIZER, p, closure, LR, num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_np = var_to_np(net(net_input))\n",
    "q = plot_image_grid([np.clip(out_np, 0, 1), img_np], factor=13);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
